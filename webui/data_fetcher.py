#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
DOGE/USDT WebUI æ•°æ®è·å–å’Œé¢„å¤„ç†è„šæœ¬
åŠŸèƒ½ï¼šè·å–æœ€æ–°400å°æ—¶çš„DOGE/USDTæ°¸ç»­åˆçº¦1å°æ—¶Kçº¿æ•°æ®ï¼Œé¢„å¤„ç†åä¿å­˜ä¸ºKronoså¯ç”¨æ ¼å¼
"""

import os
import sys
import time
import glob
import pandas as pd
import numpy as np
from datetime import datetime
from binance import Client
import csv


def ms2str(ms):
    """å°†æ¯«ç§’æ—¶é—´æˆ³è½¬æ¢ä¸ºå¯è¯»å­—ç¬¦ä¸²"""
    from datetime import timezone
    return datetime.fromtimestamp(ms / 1000, tz=timezone.utc).strftime("%Y-%m-%d %H:%M:%S")


def get_klines_with_retry(client, params, max_retries=3):
    """å¸¦é‡è¯•æœºåˆ¶çš„USDâ“ˆ-Måˆçº¦Kçº¿æ•°æ®è·å–"""
    for attempt in range(max_retries):
        try:
            return client.futures_klines(**params)
        except Exception as e:
            print(f"  ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                print("  è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ•°æ®è·å–å¤±è´¥")
                raise e


def fetch_latest_klines(hours=400):
    """
    è·å–æœ€æ–°æŒ‡å®šå°æ—¶æ•°çš„DOGE/USDTæ°¸ç»­åˆçº¦Kçº¿æ•°æ®
    
    Args:
        hours (int): è·å–çš„å°æ—¶æ•°ï¼Œé»˜è®¤400
        
    Returns:
        list: Kçº¿æ•°æ®åˆ—è¡¨
    """
    print(f"ğŸ”„ å¼€å§‹è·å–DOGE/USDTæœ€æ–°{hours}å°æ—¶Kçº¿æ•°æ®...")
    
    client = Client()
    symbol = "DOGEUSDT"
    interval = "1h"
    
    all_klines = []
    processed_times = set()  # ç”¨äºé¿å…é‡å¤æ•°æ®
    target_count = hours
    
    # ä»å½“å‰æ—¶é—´å¼€å§‹ï¼Œå‘è¿‡å»è·å–
    end_time = int(time.time() * 1000)
    
    while len(all_klines) < target_count:
        # è®¡ç®—è¿˜éœ€è¦å¤šå°‘æ¡æ•°æ®
        remaining = target_count - len(all_klines)
        limit = min(1500, remaining)  # æ¯æ¬¡æœ€å¤š1500æ¡
        
        try:
            params = {
                "symbol": symbol, 
                "interval": interval, 
                "limit": limit, 
                "endTime": end_time
            }
            
            klines = get_klines_with_retry(client, params)
            
            if not klines:
                print("  æ²¡æœ‰æ›´å¤šæ•°æ®å¯è·å–")
                break
            
            # è¿‡æ»¤é‡å¤æ•°æ®
            new_klines = []
            for kline in klines:
                if kline[0] not in processed_times:
                    new_klines.append(kline)
                    processed_times.add(kline[0])
            
            if not new_klines:
                print("  æ‰€æœ‰æ•°æ®éƒ½å·²å¤„ç†è¿‡")
                break
                
            # æ·»åŠ æ–°æ•°æ®ï¼ˆæ³¨æ„ï¼šAPIè¿”å›çš„æ˜¯å€’åºï¼Œæœ€æ–°çš„åœ¨å‰ï¼‰
            all_klines.extend(new_klines)
            print(f"  å·²è·å– {len(all_klines)}/{target_count} æ¡æ•°æ®")
            
            # è®¾ç½®ä¸‹ä¸€è½®çš„ç»“æŸæ—¶é—´ä¸ºå½“å‰æ‰¹æ¬¡æœ€æ—©çš„æ—¶é—´-1
            first_open_time = new_klines[-1][0]  # æœ€æ—©çš„ä¸€æ¡
            end_time = first_open_time - 1
            
            # å¦‚æœè¿™æ¬¡è¿”å›çš„æ•°æ®ä¸å¤Ÿlimitï¼Œè¯´æ˜æ²¡æœ‰æ›´å¤šå†å²æ•°æ®
            if len(klines) < limit:
                print("  å·²åˆ°è¾¾æœ€æ—©å†å²æ•°æ®")
                break
                
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            time.sleep(0.1)
            
        except Exception as e:
            print(f"  è·å–æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            raise e
    
    if all_klines:
        # æŒ‰æ—¶é—´å‡åºæ’åºï¼ˆä»è¿‡å»åˆ°ç°åœ¨ï¼‰
        all_klines.sort(key=lambda x: x[0])
        print(f"âœ… æˆåŠŸè·å– {len(all_klines)} æ¡Kçº¿æ•°æ®")
        print(f"  æ—¶é—´èŒƒå›´: {ms2str(all_klines[0][0])} åˆ° {ms2str(all_klines[-1][0])}")
        return all_klines
    else:
        raise Exception("æ²¡æœ‰è·å–åˆ°ä»»ä½•Kçº¿æ•°æ®")


def preprocess_data(raw_data):
    """
    é¢„å¤„ç†Kçº¿æ•°æ®ï¼Œè½¬æ¢ä¸ºKronoséœ€è¦çš„æ ¼å¼
    
    Args:
        raw_data (list): åŸå§‹Kçº¿æ•°æ®
        
    Returns:
        pd.DataFrame: å¤„ç†åçš„æ•°æ®æ¡†
    """
    print("ğŸ”„ å¼€å§‹æ•°æ®é¢„å¤„ç†...")
    
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(raw_data, columns=[
        "open_time", "open", "high", "low", "close", "volume",
        "close_time", "quote_asset_volume", "number_of_trades",
        "taker_buy_base", "taker_buy_quote", "ignore"
    ])
    
    # è½¬æ¢æ•°æ®ç±»å‹
    df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')
    df['open'] = df['open'].astype(float)
    df['high'] = df['high'].astype(float)
    df['low'] = df['low'].astype(float)
    df['close'] = df['close'].astype(float)
    df['volume'] = df['volume'].astype(float)
    df['quote_asset_volume'] = df['quote_asset_volume'].astype(float)
    
    # é‡å‘½åä¸ºKronosæœŸæœ›çš„æ ¼å¼ï¼Œä½¿ç”¨BinanceçœŸå®æˆäº¤é¢
    df = df.rename(columns={
        'open_time': 'timestamps',
        'quote_asset_volume': 'amount'
    })
    
    # é€‰æ‹©Kronoséœ€è¦çš„åˆ—
    df_processed = df[['timestamps', 'open', 'high', 'low', 'close', 'volume', 'amount']].copy()
    
    # éªŒè¯æ•°æ®å®Œæ•´æ€§
    if df_processed.isnull().any().any():
        print("  âš ï¸ æ£€æµ‹åˆ°ç¼ºå¤±å€¼ï¼Œè¿›è¡Œå¤„ç†...")
        df_processed = df_processed.fillna(method='ffill').fillna(method='bfill')
    
    print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œæœ€ç»ˆæ•°æ®å½¢çŠ¶: {df_processed.shape}")
    print("  åˆ—å:", df_processed.columns.tolist())
    
    return df_processed


def generate_timestamped_filename():
    """ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    return f"dogeusdt_{timestamp}.csv"


def save_processed_data(df, data_dir="data"):
    """
    ä¿å­˜å¤„ç†åçš„æ•°æ®åˆ°æŒ‡å®šç›®å½•
    
    Args:
        df (pd.DataFrame): å¤„ç†åçš„æ•°æ®æ¡†
        data_dir (str): æ•°æ®ç›®å½•è·¯å¾„
        
    Returns:
        str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    print("ğŸ”„ ä¿å­˜å¤„ç†åçš„æ•°æ®...")
    
    # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    os.makedirs(data_dir, exist_ok=True)
    
    # ç”Ÿæˆæ—¶é—´æˆ³æ–‡ä»¶å
    filename = generate_timestamped_filename()
    filepath = os.path.join(data_dir, filename)
    
    # ä¿å­˜ä¸ºCSV
    df.to_csv(filepath, index=False, encoding='utf-8')
    
    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
    print(f"  æ–‡ä»¶å¤§å°: {os.path.getsize(filepath) / 1024:.2f} KB")
    
    return filepath


def get_latest_data_file(data_dir="data"):
    """
    è·å–æ•°æ®ç›®å½•ä¸­æœ€æ–°çš„æ•°æ®æ–‡ä»¶
    
    Args:
        data_dir (str): æ•°æ®ç›®å½•è·¯å¾„
        
    Returns:
        str: æœ€æ–°æ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰æ–‡ä»¶åˆ™è¿”å›None
    """
    pattern = os.path.join(data_dir, "dogeusdt_*.csv")
    data_files = glob.glob(pattern)
    
    if not data_files:
        return None
    
    # æŒ‰æ–‡ä»¶åˆ›å»ºæ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
    latest_file = max(data_files, key=os.path.getctime)
    return latest_file


def validate_data_file(filepath):
    """
    éªŒè¯æ•°æ®æ–‡ä»¶çš„æœ‰æ•ˆæ€§
    
    Args:
        filepath (str): æ•°æ®æ–‡ä»¶è·¯å¾„
        
    Returns:
        bool: æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
    """
    try:
        df = pd.read_csv(filepath)
        
        # æ£€æŸ¥å¿…éœ€çš„åˆ—
        required_cols = ['timestamps', 'open', 'high', 'low', 'close', 'volume', 'amount']
        if not all(col in df.columns for col in required_cols):
            return False
        
        # æ£€æŸ¥æ•°æ®é‡
        if len(df) < 100:  # è‡³å°‘è¦æœ‰100æ¡æ•°æ®
            return False
            
        # æ£€æŸ¥æ•°æ®ç±»å‹
        df['timestamps'] = pd.to_datetime(df['timestamps'])
        
        return True
    except Exception:
        return False


def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®ç¼–ç ä»¥é¿å…Windowså‘½ä»¤è¡Œæ˜¾ç¤ºé—®é¢˜
    import sys
    import io
    if sys.platform == "win32":
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    
    print("DOGE/USDT æ•°æ®è·å–å’Œé¢„å¤„ç†å·¥å…·")
    print("=" * 50)
    
    try:
        # 1. è·å–æœ€æ–°400å°æ—¶æ•°æ®
        raw_data = fetch_latest_klines(hours=400)
        
        # 2. æ•°æ®é¢„å¤„ç†
        processed_df = preprocess_data(raw_data)
        
        # 3. ä¿å­˜æ•°æ®
        filepath = save_processed_data(processed_df)
        
        # 4. éªŒè¯ä¿å­˜çš„æ–‡ä»¶
        if validate_data_file(filepath):
            print("âœ… æ•°æ®æ–‡ä»¶éªŒè¯é€šè¿‡")
        else:
            print("âŒ æ•°æ®æ–‡ä»¶éªŒè¯å¤±è´¥")
            return
        
        # 5. æ˜¾ç¤ºæ‘˜è¦ä¿¡æ¯
        print("\nğŸ“Š æ•°æ®æ‘˜è¦:")
        print(f"  æ•°æ®æ¡æ•°: {len(processed_df)}")
        print(f"  æ—¶é—´èŒƒå›´: {processed_df['timestamps'].iloc[0]} åˆ° {processed_df['timestamps'].iloc[-1]}")
        print(f"  ä»·æ ¼èŒƒå›´: {processed_df['close'].min():.6f} - {processed_df['close'].max():.6f}")
        print(f"  å¹³å‡äº¤æ˜“é‡: {processed_df['volume'].mean():.2f}")
        
        # 6. æ˜¾ç¤ºæœ€æ–°æ•°æ®æ–‡ä»¶ä¿¡æ¯
        latest_file = get_latest_data_file()
        if latest_file:
            print(f"\nğŸ“ æœ€æ–°æ•°æ®æ–‡ä»¶: {latest_file}")
        
        print("\nğŸ‰ æ•°æ®è·å–å’Œé¢„å¤„ç†å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
