#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Kronos DOGE/USDT æ¨¡å‹é¢„æµ‹æœåŠ¡
åŸºäºkronos_prediction_eval.pyçš„é«˜ç²¾åº¦é¢„æµ‹æ–¹æ³•
"""

import os
import sys
import json
import numpy as np
import pandas as pd
import torch
from datetime import datetime, timedelta
import pytz
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('../')

# å¯¼å…¥Kronosæ¨¡å‹
try:
    from model.kronos import KronosTokenizer, Kronos, KronosPredictor
    KRONOS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Kronosæ¨¡å‹å¯¼å…¥å¤±è´¥: {e}")
    KRONOS_AVAILABLE = False


def convert_to_beijing_time(timestamp_series, format_str='%Y-%m-%d %H:%M:%S'):
    """
    å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´æ˜¾ç¤ºæ ¼å¼
    
    Args:
        timestamp_series: pandas Seriesæˆ–å•ä¸ªæ—¶é—´æˆ³
        format_str: æ—¶é—´æ ¼å¼å­—ç¬¦ä¸²
        
    Returns:
        è½¬æ¢åçš„åŒ—äº¬æ—¶é—´å­—ç¬¦ä¸²æˆ–åˆ—è¡¨
    """
    beijing_tz = pytz.timezone('Asia/Shanghai')
    
    if isinstance(timestamp_series, pd.Series):
        # å¦‚æœæ˜¯UTCæ—¶é—´ï¼Œå…ˆè½¬æ¢ä¸ºUTCæ—¶åŒºæ„ŸçŸ¥ï¼Œå†è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
        if timestamp_series.dt.tz is None:
            # å‡è®¾åŸå§‹æ—¶é—´æ˜¯UTCæ—¶é—´
            utc_times = timestamp_series.dt.tz_localize('UTC')
        else:
            utc_times = timestamp_series.dt.tz_convert('UTC')
        
        # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
        beijing_times = utc_times.dt.tz_convert(beijing_tz)
        return beijing_times.dt.strftime(format_str).tolist()
    else:
        # å•ä¸ªæ—¶é—´æˆ³
        if isinstance(timestamp_series, str):
            timestamp_series = pd.to_datetime(timestamp_series)
        
        if timestamp_series.tz is None:
            # å‡è®¾æ˜¯UTCæ—¶é—´
            utc_time = timestamp_series.tz_localize('UTC')
        else:
            utc_time = timestamp_series.tz_convert('UTC')
        
        # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
        beijing_time = utc_time.tz_convert(beijing_tz)
        return beijing_time.strftime(format_str)


class KronosModelService:
    """Kronosæ¨¡å‹é¢„æµ‹æœåŠ¡ç±»"""
    
    def __init__(self):
        self.tokenizer = None
        self.model = None
        self.predictor = None
        self.device = None
        self.loaded = False
        self.model_info = {}
    
    def check_availability(self):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        return KRONOS_AVAILABLE
    
    def load_model(self, device=None):
        """
        åŠ è½½Kronosæ¨¡å‹
        
        Args:
            device: è®¾å¤‡é€‰æ‹© ('cpu', 'cuda', 'mps', 'auto')
        """
        if not KRONOS_AVAILABLE:
            raise RuntimeError("Kronosæ¨¡å‹ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥modelæ¨¡å—å®‰è£…")
        
        if self.loaded:
            print("âœ… æ¨¡å‹å·²åŠ è½½")
            return True
        
        try:
            print("ğŸ”„ å¼€å§‹åŠ è½½Kronos DOGEæ¨¡å‹...")
            
            # è®¾å¤‡é€‰æ‹©
            self.device = self._select_device(device)
            print(f"ğŸ–¥ï¸ é€‰æ‹©è®¾å¤‡: {self.device}")
            
            # ä»Hugging FaceåŠ è½½å¾®è°ƒåçš„æ¨¡å‹
            print("ğŸ“¦ ä»Hugging FaceåŠ è½½å¾®è°ƒæ¨¡å‹...")
            self.tokenizer = KronosTokenizer.from_pretrained("Ramond-e/doge-kronos-tokenizer")
            self.model = Kronos.from_pretrained("Ramond-e/doge-kronos-predictor")
            
            # åˆ›å»ºé¢„æµ‹å™¨ - ä½¿ç”¨è¯„ä¼°æ–‡ä»¶ä¸­çš„æœ€ä½³é…ç½®
            print("ğŸ”§ åˆ›å»ºé¢„æµ‹å™¨...")
            self.predictor = KronosPredictor(
                model=self.model,
                tokenizer=self.tokenizer,
                device=self.device,
                max_context=512,  # ä¸è¯„ä¼°æ–‡ä»¶ä¸€è‡´
                clip=5           # æ•°æ®æ ‡å‡†åŒ–å‰ªåˆ‡èŒƒå›´
            )
            
            # è®°å½•æ¨¡å‹ä¿¡æ¯
            self.model_info = {
                'tokenizer_source': 'Ramond-e/doge-kronos-tokenizer',
                'model_source': 'Ramond-e/doge-kronos-predictor',
                'device': self.device,
                'max_context': 512,
                'clip_range': 5,
                'loaded_at': datetime.now().isoformat()
            }
            
            self.loaded = True
            print("âœ… Kronosæ¨¡å‹åŠ è½½æˆåŠŸ!")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.loaded = False
            return False
    
    def _select_device(self, device):
        """æ™ºèƒ½è®¾å¤‡é€‰æ‹©"""
        if device == 'auto' or device is None:
            # è‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡
            if torch.cuda.is_available():
                return 'cuda'
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                return 'mps'
            else:
                return 'cpu'
        
        elif device == 'cuda':
            if torch.cuda.is_available():
                return 'cuda'
            else:
                print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œå›é€€åˆ°CPU")
                return 'cpu'
        
        elif device == 'mps':
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                return 'mps'
            else:
                print("âš ï¸ MPSä¸å¯ç”¨ï¼Œå›é€€åˆ°CPU")
                return 'cpu'
        
        else:
            return 'cpu'
    
    def predict_future(self, data_df, pred_hours=120, temperature=1.0, top_p=0.9, sample_count=1):
        """
        é¢„æµ‹æœªæ¥ä»·æ ¼è¶‹åŠ¿
        
        Args:
            data_df: å†å²æ•°æ®DataFrame (å¿…é¡»åŒ…å«OHLCVå’Œamountåˆ—)
            pred_hours: é¢„æµ‹å°æ—¶æ•° (é»˜è®¤120å°æ—¶ï¼Œ5å¤©)
            temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶é¢„æµ‹éšæœºæ€§ (0.1-2.0)
            top_p: æ ¸é‡‡æ ·å‚æ•°ï¼Œæ§åˆ¶é¢„æµ‹å¤šæ ·æ€§ (0.1-1.0)
            sample_count: é‡‡æ ·æ¬¡æ•° (1-5)
        
        Returns:
            dict: åŒ…å«é¢„æµ‹ç»“æœå’Œåˆ†æçš„å­—å…¸
        """
        if not self.loaded:
            raise RuntimeError("æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨load_model()")
        
        # å‚æ•°éªŒè¯
        self._validate_prediction_params(temperature, top_p, sample_count)
        
        # æ•°æ®éªŒè¯å’Œå‡†å¤‡
        prepared_data = self._prepare_data(data_df)
        
        try:
            print(f"ğŸ”® å¼€å§‹é¢„æµ‹: T={temperature}, top_p={top_p}, samples={sample_count}")
            print(f"ğŸ“Š å†å²æ•°æ®: {len(prepared_data['x_df'])}å°æ—¶, é¢„æµ‹é•¿åº¦: {pred_hours}å°æ—¶")
            
            # æ‰§è¡Œé¢„æµ‹ - ä½¿ç”¨ä¸è¯„ä¼°æ–‡ä»¶ç›¸åŒçš„æ–¹æ³•
            pred_df = self.predictor.predict(
                df=prepared_data['x_df'],
                x_timestamp=prepared_data['x_timestamp'],
                y_timestamp=prepared_data['y_timestamp'],
                pred_len=pred_hours,
                T=temperature,
                top_k=0,         # å…³é—­top-ké‡‡æ ·ï¼Œä½¿ç”¨top-p
                top_p=top_p,
                sample_count=sample_count,
                verbose=True     # æ˜¾ç¤ºé¢„æµ‹è¿›åº¦
            )
            
            print("âœ… é¢„æµ‹å®Œæˆ!")
            
            # åå¤„ç†å’Œåˆ†æ
            result = self._post_process_prediction(
                historical_df=prepared_data['x_df'],
                prediction_df=pred_df,
                historical_timestamps=prepared_data['x_timestamp'],
                prediction_timestamps=prepared_data['y_timestamp'],
                parameters={
                    'temperature': temperature,
                    'top_p': top_p,
                    'sample_count': sample_count,
                    'pred_hours': pred_hours,
                    'historical_hours': len(prepared_data['x_df'])
                }
            )
            
            return result
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            raise RuntimeError(f"é¢„æµ‹æ‰§è¡Œå¤±è´¥: {str(e)}")
    
    def _validate_prediction_params(self, temperature, top_p, sample_count):
        """éªŒè¯é¢„æµ‹å‚æ•°"""
        if not (0.1 <= temperature <= 2.0):
            raise ValueError("Temperatureå¿…é¡»åœ¨0.1-2.0ä¹‹é—´")
        if not (0.1 <= top_p <= 1.0):
            raise ValueError("top_på¿…é¡»åœ¨0.1-1.0ä¹‹é—´")
        if not (1 <= sample_count <= 5):
            raise ValueError("sample_countå¿…é¡»åœ¨1-5ä¹‹é—´")
    
    def _prepare_data(self, data_df):
        """å‡†å¤‡é¢„æµ‹æ•°æ®"""
        # éªŒè¯å¿…éœ€åˆ—
        required_cols = ['timestamps', 'open', 'high', 'low', 'close', 'volume', 'amount']
        missing_cols = [col for col in required_cols if col not in data_df.columns]
        if missing_cols:
            raise ValueError(f"æ•°æ®ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
        
        # æ•°æ®æ¸…ç†
        df = data_df.copy()
        df['timestamps'] = pd.to_datetime(df['timestamps'])
        df = df.sort_values('timestamps').reset_index(drop=True)
        
        # æ£€æŸ¥æ•°æ®è´¨é‡
        if df[['open', 'high', 'low', 'close', 'volume', 'amount']].isnull().any().any():
            raise ValueError("æ•°æ®åŒ…å«ç©ºå€¼ï¼Œè¯·æ£€æŸ¥æ•°æ®è´¨é‡")
        
        # ä½¿ç”¨æœ€æ–°400å°æ—¶æ•°æ®ä½œä¸ºå†å²æ•°æ®ï¼ˆä¸è¯„ä¼°æ–‡ä»¶ä¸€è‡´ï¼‰
        lookback = min(400, len(df))
        x_df = df.tail(lookback)[['open', 'high', 'low', 'close', 'volume', 'amount']].copy()
        x_timestamp = df.tail(lookback)['timestamps'].copy()
        
        # ç”Ÿæˆæœªæ¥æ—¶é—´æˆ³
        last_time = x_timestamp.iloc[-1]
        future_timestamps = pd.date_range(
            start=last_time + pd.Timedelta(hours=1),
            periods=120,  # å›ºå®šé¢„æµ‹120å°æ—¶
            freq='h'
        )
        y_timestamp = pd.Series(future_timestamps)
        
        return {
            'x_df': x_df.reset_index(drop=True),
            'x_timestamp': x_timestamp.reset_index(drop=True),
            'y_timestamp': y_timestamp,
            'last_price': df['close'].iloc[-1],
            'last_volume': df['volume'].iloc[-1]
        }
    
    def _post_process_prediction(self, historical_df, prediction_df, historical_timestamps, 
                                prediction_timestamps, parameters):
        """åå¤„ç†é¢„æµ‹ç»“æœ"""
        
        # æ·»åŠ æ—¶é—´æˆ³
        prediction_df = prediction_df.copy()
        prediction_df['timestamps'] = prediction_timestamps.values
        
        # åŸºç¡€ç»Ÿè®¡
        current_price = historical_df['close'].iloc[-1]
        future_price = prediction_df['close'].iloc[-1]
        price_change = future_price - current_price
        price_change_pct = (price_change / current_price) * 100
        
        # è¶‹åŠ¿åˆ†æ
        trend_analysis = self._analyze_trend(historical_df, prediction_df, current_price)
        
        # æ³¢åŠ¨æ€§åˆ†æ
        volatility_analysis = self._analyze_volatility(historical_df, prediction_df)
        
        # å›¾è¡¨æ•°æ®
        chart_data = self._generate_chart_data(historical_df, prediction_df, 
                                              historical_timestamps, prediction_timestamps)
        
        # é¢„æµ‹è´¨é‡æŒ‡æ ‡
        quality_metrics = self._calculate_quality_metrics(prediction_df, parameters)
        
        return {
            'success': True,
            'prediction_data': prediction_df.to_dict('records'),
            'historical_data': historical_df.to_dict('records'),
            'trend_analysis': trend_analysis,
            'volatility_analysis': volatility_analysis,
            'chart_data': chart_data,
            'quality_metrics': quality_metrics,
            'parameters': parameters,
            'model_info': self.model_info,
            'generated_at': datetime.now().isoformat()
        }
    
    def _analyze_trend(self, historical_df, prediction_df, current_price):
        """è¶‹åŠ¿åˆ†æ"""
        future_price = prediction_df['close'].iloc[-1]
        price_change = future_price - current_price
        price_change_pct = (price_change / current_price) * 100
        
        # è¶‹åŠ¿å¼ºåº¦åˆ†ç±»
        if price_change_pct > 5:
            trend = "å¼ºçƒˆä¸Šæ¶¨"
            trend_color = "#00C851"
            trend_emoji = "ğŸš€"
        elif price_change_pct > 2:
            trend = "ä¸Šæ¶¨"
            trend_color = "#4CAF50"
            trend_emoji = "ğŸ“ˆ"
        elif price_change_pct > -2:
            trend = "æ¨ªç›˜"
            trend_color = "#FF9800"
            trend_emoji = "â¡ï¸"
        elif price_change_pct > -5:
            trend = "ä¸‹è·Œ"
            trend_color = "#FF5722"
            trend_emoji = "ğŸ“‰"
        else:
            trend = "å¼ºçƒˆä¸‹è·Œ"
            trend_color = "#F44336"
            trend_emoji = "â¬‡ï¸"
        
        # ä»·æ ¼åŒºé—´
        pred_min = prediction_df['close'].min()
        pred_max = prediction_df['close'].max()
        
        # å†å²æ³¢åŠ¨ç‡
        hist_returns = historical_df['close'].pct_change().dropna()
        hist_volatility = hist_returns.std() * np.sqrt(24) * 100  # å¹´åŒ–æ³¢åŠ¨ç‡
        
        return {
            'current_price': float(current_price),
            'predicted_price': float(future_price),
            'price_change': float(price_change),
            'price_change_pct': float(price_change_pct),
            'trend': trend,
            'trend_color': trend_color,
            'trend_emoji': trend_emoji,
            'historical_volatility': float(hist_volatility),
            'predicted_range': {
                'min': float(pred_min),
                'max': float(pred_max),
                'range_pct': float((pred_max - pred_min) / current_price * 100)
            }
        }
    
    def _analyze_volatility(self, historical_df, prediction_df):
        """æ³¢åŠ¨æ€§åˆ†æ"""
        # å†å²æ³¢åŠ¨ç‡
        hist_returns = historical_df['close'].pct_change().dropna()
        hist_volatility = hist_returns.std() * np.sqrt(24) * 100  # å¹´åŒ–æ³¢åŠ¨ç‡
        
        # é¢„æµ‹æ³¢åŠ¨ç‡
        pred_returns = prediction_df['close'].pct_change().dropna()
        pred_volatility = pred_returns.std() * np.sqrt(24) * 100  # å¹´åŒ–æ³¢åŠ¨ç‡
        
        return {
            'historical_volatility': float(hist_volatility),
            'predicted_volatility': float(pred_volatility),
            'volatility_change': float(pred_volatility - hist_volatility),
            'volatility_level': self._classify_volatility(pred_volatility)
        }
    
    def _classify_volatility(self, volatility):
        """æ³¢åŠ¨ç‡æ°´å¹³åˆ†ç±»"""
        if volatility < 20:
            return "ä½æ³¢åŠ¨"
        elif volatility < 40:
            return "ä¸­ç­‰æ³¢åŠ¨"
        elif volatility < 60:
            return "é«˜æ³¢åŠ¨"
        else:
            return "æé«˜æ³¢åŠ¨"
    
    def _generate_chart_data(self, historical_df, prediction_df, hist_timestamps, pred_timestamps):
        """ç”Ÿæˆå›¾è¡¨æ•°æ®ï¼ˆæ—¶é—´æ˜¾ç¤ºä¸ºåŒ—äº¬æ—¶é—´ï¼‰"""
        return {
            'historical': {
                'timestamps': convert_to_beijing_time(hist_timestamps),
                'open': historical_df['open'].tolist(),
                'high': historical_df['high'].tolist(),
                'low': historical_df['low'].tolist(),
                'close': historical_df['close'].tolist(),
                'volume': historical_df['volume'].tolist()
            },
            'prediction': {
                'timestamps': convert_to_beijing_time(pred_timestamps),
                'open': prediction_df['open'].tolist(),
                'high': prediction_df['high'].tolist(),
                'low': prediction_df['low'].tolist(),
                'close': prediction_df['close'].tolist(),
                'volume': prediction_df['volume'].tolist()
            }
        }
    
    def _calculate_quality_metrics(self, prediction_df, parameters):
        """è®¡ç®—é¢„æµ‹è´¨é‡æŒ‡æ ‡"""
        # åŸºäºæ¸©åº¦å’Œtop_pè®¡ç®—é¢„æµ‹è´¨é‡è¯„åˆ†
        temp_score = 100 - abs(parameters['temperature'] - 1.0) * 30  # æœ€ä½³æ¸©åº¦1.0
        diversity_score = parameters['top_p'] * 100  # top_pè¶Šé«˜å¤šæ ·æ€§è¶Šå¥½
        sample_score = min(parameters['sample_count'] * 20, 100)  # æ ·æœ¬æ•°åŠ åˆ†
        
        overall_score = (temp_score + diversity_score + sample_score) / 3
        
        # é¢„æµ‹ç¨³å®šæ€§ï¼ˆåŸºäºä»·æ ¼å˜åŒ–çš„æ ‡å‡†å·®ï¼‰
        price_stability = 100 - (prediction_df['close'].std() / prediction_df['close'].mean() * 100)
        price_stability = max(0, min(100, price_stability))
        
        return {
            'overall_quality_score': float(overall_score),
            'temperature_optimality': float(temp_score),
            'diversity_score': float(diversity_score),
            'sample_adequacy': float(sample_score),
            'prediction_stability': float(price_stability),
            'confidence_level': self._calculate_confidence(overall_score)
        }
    
    def _calculate_confidence(self, quality_score):
        """è®¡ç®—ç½®ä¿¡åº¦æ°´å¹³"""
        if quality_score >= 90:
            return "éå¸¸é«˜"
        elif quality_score >= 80:
            return "é«˜"
        elif quality_score >= 70:
            return "ä¸­ç­‰"
        elif quality_score >= 60:
            return "è¾ƒä½"
        else:
            return "ä½"
    
    def get_model_status(self):
        """è·å–æ¨¡å‹çŠ¶æ€"""
        return {
            'available': self.check_availability(),
            'loaded': self.loaded,
            'device': self.device,
            'model_info': self.model_info if self.loaded else None
        }


# å…¨å±€æ¨¡å‹æœåŠ¡å®ä¾‹
model_service = KronosModelService()


def get_model_service():
    """è·å–æ¨¡å‹æœåŠ¡å®ä¾‹"""
    return model_service
