#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
åŸºäºåŸKronosé¡¹ç›®é¢„æµ‹ç¤ºä¾‹çš„DOGE/USDTæ¨¡å‹è¯„ä¼°è„šæœ¬
ä½¿ç”¨5æœˆæœŸé—´600å°æ—¶æ•°æ®ï¼šå‰80%é¢„æµ‹å20%ï¼Œä¸çœŸå®å€¼å¯¹æ¯”
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import sys
import os
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append("../../")
sys.path.append("../")

from model import Kronos, KronosTokenizer, KronosPredictor

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def plot_prediction(kline_df, pred_df):
    """
    å¯è§†åŒ–é¢„æµ‹ç»“æœ
    """
    pred_df.index = kline_df.index[-pred_df.shape[0]:]
    sr_close = kline_df['close']
    sr_pred_close = pred_df['close']
    sr_close.name = 'Ground Truth'
    sr_pred_close.name = "Prediction"

    sr_volume = kline_df['volume']
    sr_pred_volume = pred_df['volume']
    sr_volume.name = 'Ground Truth'
    sr_pred_volume.name = "Prediction"

    close_df = pd.concat([sr_close, sr_pred_close], axis=1)
    volume_df = pd.concat([sr_volume, sr_pred_volume], axis=1)

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), sharex=True)

    # ç»˜åˆ¶Closeä»·æ ¼å¯¹æ¯”
    ax1.plot(close_df['Ground Truth'], label='Ground Truth', color='blue', linewidth=2)
    ax1.plot(close_df['Prediction'], label='Prediction', color='red', linewidth=2, linestyle='--')
    ax1.set_ylabel('Close Price (USDT)', fontsize=14, fontweight='bold')
    ax1.set_title('DOGE/USDT Close Price Prediction vs Ground Truth', fontsize=16, fontweight='bold')
    ax1.legend(loc='upper left', fontsize=12)
    ax1.grid(True, alpha=0.3)

    # ç»˜åˆ¶äº¤æ˜“é‡å¯¹æ¯”
    ax2.plot(volume_df['Ground Truth'], label='Ground Truth', color='blue', linewidth=2)
    ax2.plot(volume_df['Prediction'], label='Prediction', color='red', linewidth=2, linestyle='--')
    ax2.set_ylabel('Volume', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Time', fontsize=14, fontweight='bold')
    ax2.set_title('DOGE/USDT Volume Prediction vs Ground Truth', fontsize=16, fontweight='bold')
    ax2.legend(loc='upper left', fontsize=12)
    ax2.grid(True, alpha=0.3)

    # æ·»åŠ åˆ†éš”çº¿æ ‡ç¤ºé¢„æµ‹å¼€å§‹ä½ç½®
    split_point = len(close_df) - len(pred_df)
    ax1.axvline(x=close_df.index[split_point], color='black', linestyle=':', alpha=0.7, linewidth=2)
    ax2.axvline(x=close_df.index[split_point], color='black', linestyle=':', alpha=0.7, linewidth=2)
    
    # æ·»åŠ æ–‡æœ¬æ ‡æ³¨
    ax1.text(close_df.index[split_point], ax1.get_ylim()[1]*0.95, 'Prediction Start', 
             rotation=90, verticalalignment='top', fontsize=12, fontweight='bold')

    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    save_path = "doge_prediction_results.png"
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"ğŸ“Š é¢„æµ‹ç»“æœå›¾è¡¨å·²ä¿å­˜: {save_path}")
    plt.show()

def calculate_metrics(pred_df, true_df):
    """
    è®¡ç®—é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
    """
    results = {}
    
    for col in ['close', 'volume']:
        pred_values = pred_df[col].values
        true_values = true_df[col].values
        
        # åŸºæœ¬è¯¯å·®æŒ‡æ ‡
        mse = np.mean((pred_values - true_values) ** 2)
        rmse = np.sqrt(mse)
        mae = np.mean(np.abs(pred_values - true_values))
        mape = np.mean(np.abs((true_values - pred_values) / (true_values + 1e-8))) * 100
        
        # æ–¹å‘å‡†ç¡®ç‡
        pred_direction = np.sign(np.diff(pred_values))
        true_direction = np.sign(np.diff(true_values))
        direction_accuracy = np.mean(pred_direction == true_direction)
        
        # ç›¸å…³ç³»æ•°
        correlation = np.corrcoef(pred_values, true_values)[0, 1]
        if np.isnan(correlation):
            correlation = 0.0
        
        results[col] = {
            'MSE': mse,
            'RMSE': rmse,
            'MAE': mae,
            'MAPE': mape,
            'Direction_Accuracy': direction_accuracy,
            'Correlation': correlation
        }
    
    return results

def load_and_prepare_data():
    """
    åŠ è½½å¹¶å‡†å¤‡DOGE/USDTæ•°æ®
    """
    print("ğŸ”„ åŠ è½½DOGE/USDTæ•°æ®...")
    
    # åŠ è½½åŸå§‹æ•°æ®
    data_path = "../../get_DOGEUSDT_data/dogeusdt_1h_all_klines.csv"
    df = pd.read_csv(data_path)
    
    print(f"  åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
    
    # è½¬æ¢æ—¶é—´æˆ³
    df['timestamps'] = pd.to_datetime(df['open_time'], unit='ms')
    
    # é€‰æ‹©éœ€è¦çš„åˆ—å¹¶é‡å‘½åä»¥åŒ¹é…Kronosæ ¼å¼
    df = df[['timestamps', 'open', 'high', 'low', 'close', 'volume', 'quote_asset_volume']].copy()
    df = df.rename(columns={'quote_asset_volume': 'amount'})

    # ä½¿ç”¨5æœˆæœŸé—´çš„600å°æ—¶æ•°æ®ï¼ˆæœ€ä½³è¡¨ç°æœŸï¼‰
    start_idx = len(df) - 3000  # ä»å€’æ•°ç¬¬3000å°æ—¶å¼€å§‹
    end_idx = start_idx + 600   # å–600å°æ—¶
    
    df_selected_600 = df.iloc[start_idx:end_idx].copy()
    df_selected_600 = df_selected_600.reset_index(drop=True)
    
    print(f"  ä½¿ç”¨ç¬¬{start_idx}-{end_idx}å°æ—¶çš„æ•°æ®ï¼ˆ5æœˆæœ€ä½³è¡¨ç°æœŸï¼‰ï¼Œå½¢çŠ¶: {df_selected_600.shape}")
    print(f"  æ—¶é—´èŒƒå›´: {df_selected_600['timestamps'].iloc[0]} åˆ° {df_selected_600['timestamps'].iloc[-1]}")
    
    return df_selected_600

def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸš€ DOGE/USDT Kronoså¾®è°ƒæ¨¡å‹é¢„æµ‹è¯„ä¼°")
    print("=" * 60)
    
    try:
        # 1. åŠ è½½æ•°æ®
        df = load_and_prepare_data()
        
        # 2. ä»Hugging FaceåŠ è½½å¾®è°ƒåçš„æ¨¡å‹å’Œtokenizer
        print("ğŸ”„ ä»Hugging FaceåŠ è½½å¾®è°ƒåçš„DOGE Kronosæ¨¡å‹...")
        
        try:
            tokenizer = KronosTokenizer.from_pretrained("Ramond-e/doge-kronos-tokenizer")
            model = Kronos.from_pretrained("Ramond-e/doge-kronos-predictor")
            print("  âœ… æˆåŠŸä»Hugging FaceåŠ è½½å¾®è°ƒåçš„DOGEæ¨¡å‹")
            
        except Exception as e:
            print(f"  âŒ ä»Hugging FaceåŠ è½½å¤±è´¥: {e}")
            print("  è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ¨¡å‹ä»“åº“æ˜¯å¦å¯è®¿é—®")
            raise
        
        # 3. åˆ›å»ºé¢„æµ‹å™¨
        predictor = KronosPredictor(model, tokenizer, device="cuda:0", max_context=512)
        
        # 4. å‡†å¤‡æ•°æ®åˆ†å‰²
        total_len = len(df)
        split_point = int(total_len * 0.8)  # å‰80%ç”¨äºå†å²ï¼Œå20%ç”¨äºé¢„æµ‹ç›®æ ‡
        
        lookback = split_point  # 480å°æ—¶çš„å†å²æ•°æ®
        pred_len = total_len - split_point  # 120å°æ—¶çš„é¢„æµ‹é•¿åº¦
        
        print(f"ğŸ“Š æ•°æ®åˆ†å‰²:")
        print(f"  å†å²æ•°æ®é•¿åº¦: {lookback} å°æ—¶")
        print(f"  é¢„æµ‹é•¿åº¦: {pred_len} å°æ—¶")
        print(f"  åˆ†å‰²æ—¶é—´ç‚¹: {df.loc[split_point-1, 'timestamps']}")
        
        # 5. å‡†å¤‡è¾“å…¥æ•°æ®
        x_df = df.loc[:lookback-1, ['open', 'high', 'low', 'close', 'volume', 'amount']].copy()
        x_timestamp = df.loc[:lookback-1, 'timestamps']
        y_timestamp = df.loc[lookback:lookback+pred_len-1, 'timestamps']
        
        print(f"ğŸ“ è¾“å…¥æ•°æ®å‡†å¤‡:")
        print(f"  å†å²ç‰¹å¾æ•°æ®å½¢çŠ¶: {x_df.shape}")
        print(f"  å†å²æ—¶é—´æˆ³é•¿åº¦: {len(x_timestamp)}")
        print(f"  é¢„æµ‹æ—¶é—´æˆ³é•¿åº¦: {len(y_timestamp)}")
        
        # 6. æ‰§è¡Œé¢„æµ‹
        print("ğŸ”® å¼€å§‹é¢„æµ‹...")
        
        pred_df = predictor.predict(
            df=x_df,
            x_timestamp=x_timestamp,
            y_timestamp=y_timestamp,
            pred_len=pred_len,
            T=1.0,           # æ¸©åº¦å‚æ•°
            top_p=0.9,       # top-pé‡‡æ ·
            sample_count=1,  # é‡‡æ ·æ¬¡æ•°
            verbose=True     # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        )
        
        print("âœ… é¢„æµ‹å®Œæˆ!")
        print(f"ğŸ“‹ é¢„æµ‹ç»“æœå½¢çŠ¶: {pred_df.shape}")
        print("\né¢„æµ‹æ•°æ®å¤´éƒ¨:")
        print(pred_df.head())
        
        # 7. å‡†å¤‡çœŸå®å€¼ç”¨äºå¯¹æ¯”
        true_df = df.loc[lookback:lookback+pred_len-1, ['open', 'high', 'low', 'close', 'volume', 'amount']].copy()
        true_df = true_df.reset_index(drop=True)
        
        print(f"\nğŸ“‹ çœŸå®æ•°æ®å½¢çŠ¶: {true_df.shape}")
        print("çœŸå®æ•°æ®å¤´éƒ¨:")
        print(true_df.head())
        
        # 8. è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        print("\nğŸ“Š è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
        metrics = calculate_metrics(pred_df, true_df)
        
        print("\nğŸ¯ é¢„æµ‹æ€§èƒ½è¯„ä¼°:")
        for feature, result in metrics.items():
            print(f"\n  {feature.upper()} é¢„æµ‹æ€§èƒ½:")
            print(f"    MSE: {result['MSE']:.6f}")
            print(f"    RMSE: {result['RMSE']:.6f}")
            print(f"    MAE: {result['MAE']:.6f}")
            print(f"    MAPE: {result['MAPE']:.2f}%")
            print(f"    æ–¹å‘å‡†ç¡®ç‡: {result['Direction_Accuracy']:.4f}")
            print(f"    ç›¸å…³ç³»æ•°: {result['Correlation']:.4f}")
        
        # 9. å¯è§†åŒ–ç»“æœ
        print("\nğŸ“ˆ ç”Ÿæˆé¢„æµ‹å¯è§†åŒ–...")
        
        # ç»„åˆå†å²å’Œé¢„æµ‹æ•°æ®ç”¨äºç»˜å›¾
        kline_df = df.loc[:lookback+pred_len-1].copy()
        kline_df = kline_df.set_index('timestamps')
        
        # è°ƒæ•´pred_dfçš„ç´¢å¼•ä»¥åŒ¹é…kline_df
        pred_df_for_plot = pred_df.copy()
        pred_df_for_plot.index = kline_df.index[-pred_len:]
        
        # ç»˜åˆ¶å¯¹æ¯”å›¾
        plot_prediction(kline_df, pred_df_for_plot)
        
        # 10. ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
        print("\nğŸ“ ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š...")
        
        report_content = f"""# DOGE/USDT Kronoså¾®è°ƒæ¨¡å‹é¢„æµ‹è¯„ä¼°æŠ¥å‘Š

## ğŸ“Š è¯„ä¼°æ¦‚è¦

- **è¯„ä¼°æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ•°æ®æ¥æº**: 5æœˆæœ€ä½³è¡¨ç°æœŸ600å°æ—¶DOGE/USDT Kçº¿æ•°æ®
- **æ•°æ®åˆ†å‰²**: å‰80% (480å°æ—¶) ç”¨äºå†å²ï¼Œå20% (120å°æ—¶) ç”¨äºé¢„æµ‹éªŒè¯
- **æ¨¡å‹**: å¾®è°ƒåçš„Kronos (Epoch 4 Predictor + Epoch 5 Tokenizer)

## ğŸ¯ é¢„æµ‹æ€§èƒ½æŒ‡æ ‡

### Closeä»·æ ¼é¢„æµ‹
- **MSE**: {metrics['close']['MSE']:.6f}
- **RMSE**: {metrics['close']['RMSE']:.6f}
- **MAE**: {metrics['close']['MAE']:.6f}
- **MAPE**: {metrics['close']['MAPE']:.2f}%
- **æ–¹å‘å‡†ç¡®ç‡**: {metrics['close']['Direction_Accuracy']:.4f}
- **ç›¸å…³ç³»æ•°**: {metrics['close']['Correlation']:.4f}

### Volumeäº¤æ˜“é‡é¢„æµ‹
- **MSE**: {metrics['volume']['MSE']:.6f}
- **RMSE**: {metrics['volume']['RMSE']:.6f}
- **MAE**: {metrics['volume']['MAE']:.6f}
- **MAPE**: {metrics['volume']['MAPE']:.2f}%
- **æ–¹å‘å‡†ç¡®ç‡**: {metrics['volume']['Direction_Accuracy']:.4f}
- **ç›¸å…³ç³»æ•°**: {metrics['volume']['Correlation']:.4f}

## ğŸ“ˆ æ¨¡å‹è¡¨ç°è¯„ä¼°

### Closeä»·æ ¼é¢„æµ‹è¡¨ç°
- **ç›¸å…³æ€§**: {'ä¼˜ç§€' if metrics['close']['Correlation'] > 0.7 else 'è‰¯å¥½' if metrics['close']['Correlation'] > 0.5 else 'ä¸€èˆ¬' if metrics['close']['Correlation'] > 0.3 else 'è¾ƒå·®'}
- **æ–¹å‘å‡†ç¡®ç‡**: {'ä¼˜ç§€' if metrics['close']['Direction_Accuracy'] > 0.6 else 'è‰¯å¥½' if metrics['close']['Direction_Accuracy'] > 0.5 else 'éœ€æ”¹è¿›'}
- **è¯¯å·®æ°´å¹³**: {'ä½' if metrics['close']['MAPE'] < 5 else 'ä¸­ç­‰' if metrics['close']['MAPE'] < 10 else 'è¾ƒé«˜'}

### Volumeäº¤æ˜“é‡é¢„æµ‹è¡¨ç°  
- **ç›¸å…³æ€§**: {'ä¼˜ç§€' if metrics['volume']['Correlation'] > 0.7 else 'è‰¯å¥½' if metrics['volume']['Correlation'] > 0.5 else 'ä¸€èˆ¬' if metrics['volume']['Correlation'] > 0.3 else 'è¾ƒå·®'}
- **æ–¹å‘å‡†ç¡®ç‡**: {'ä¼˜ç§€' if metrics['volume']['Direction_Accuracy'] > 0.6 else 'è‰¯å¥½' if metrics['volume']['Direction_Accuracy'] > 0.5 else 'éœ€æ”¹è¿›'}

## ğŸ’¡ ç»“è®ºä¸å»ºè®®

1. **æ¨¡å‹é€‚ç”¨æ€§**: é€‚åˆDOGE/USDTçŸ­æœŸä»·æ ¼è¶‹åŠ¿é¢„æµ‹ (120å°æ—¶å†…)
2. **æœ€ä½³åº”ç”¨åœºæ™¯**: {'é‡åŒ–äº¤æ˜“ä¿¡å·ç”Ÿæˆå’Œè¶‹åŠ¿åˆ†æ' if metrics['close']['Correlation'] > 0.5 else 'éœ€è¿›ä¸€æ­¥ä¼˜åŒ–åä½¿ç”¨'}
3. **é£é™©æç¤º**: åŠ å¯†è´§å¸å¸‚åœºæ³¢åŠ¨è¾ƒå¤§ï¼Œé¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒ

---
*è¯„ä¼°å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = "doge_prediction_evaluation_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“„ è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        # æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ‰ é¢„æµ‹è¯„ä¼°å®Œæˆ!")
        print(f"ğŸ“ˆ Closeä»·æ ¼ç›¸å…³ç³»æ•°: {metrics['close']['Correlation']:.4f}")
        print(f"ğŸ¯ Closeä»·æ ¼æ–¹å‘å‡†ç¡®ç‡: {metrics['close']['Direction_Accuracy']:.4f}")
        print(f"ğŸ“Š Closeä»·æ ¼MAPE: {metrics['close']['MAPE']:.2f}%")
        
        if metrics['close']['Correlation'] > 0.6 and metrics['close']['Direction_Accuracy'] > 0.5:
            print("ğŸ† æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼")
        elif metrics['close']['Correlation'] > 0.4 and metrics['close']['Direction_Accuracy'] > 0.45:
            print("âœ… æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼")
        else:
            print("âš ï¸ æ¨¡å‹è¡¨ç°æœ‰å¾…æ”¹è¿›")
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        raise

if __name__ == "__main__":
    main()
